---
sidebar_position: 400
title: "⭐ 功能"
---

import { TopBanners } from "@site/src/components/TopBanners";

<TopBanners />

## Open WebUI 的主要功能 ⭐

- 🚀 **轻松设置**：使用 Docker、Kubernetes、Podman、Helm Charts（`kubectl`、`kustomize`、`podman` 或 `helm`）无缝安装，提供无忧体验，支持带有捆绑 Ollama 的 `:ollama` 镜像和带有 CUDA 支持的 `:cuda`。

- 🛠️ **引导式初始设置**：清晰完成设置过程，包括在首次设置期间明确指示创建管理员账户。

- 🤝 **OpenAI API 集成**：轻松集成 OpenAI 兼容的 API，与 Ollama 模型一起进行多样化对话。可以自定义 OpenAI API URL，使 Open WebUI 与各种第三方应用程序无缝集成。

- 🛡️ **精细权限和用户组**：通过允许管理员在整个工作区中创建详细的用户角色、用户组和权限，我们确保为所有参与用户提供安全的用户环境。这种精细度不仅增强了安全性，还允许定制用户体验，培养用户之间的所有权和责任感。

- 📱 **响应式设计**：在台式电脑、笔记本电脑和移动设备上享受无缝体验。

- 📱 **移动端渐进式 Web 应用**：在移动设备上享受原生渐进式 Web 应用体验，可在 `localhost` 或个人域名上离线访问，并提供流畅的用户界面。为了使我们的 PWA 可以安装在您的设备上，它必须在安全环境中提供。这通常意味着它必须通过 HTTPS 提供服务。

  :::info

  - 要设置 PWA，您需要了解 Linux、Docker 和反向代理（如 `Nginx`、`Caddy` 或 `Traefik`）等技术。使用这些工具可以帮助简化构建和部署满足您需求的 PWA 的过程。虽然没有"一键安装"选项，而且您通过 HTTPS 安全部署 Open WebUI 实例的可用选项需要用户经验，但使用这些资源可以使创建和部署满足您需求的 PWA 变得更容易。

  :::

- ✒️🔢 **完整的 Markdown 和 LaTeX 支持**：通过全面的 Markdown、LaTex 和富文本功能提升您的 LLM 体验，实现丰富的交互。

- 🧩 **模型构建器**：直接从 Open WebUI 轻松创建基于 Ollama 基础模型的自定义模型。创建和添加自定义角色和代理，自定义模型元素，并通过 [Open WebUI Community](https://openwebui.com/) 集成轻松导入模型。

- 📚 **本地和远程 RAG 集成**：通过我们在聊天中的尖端检索增强生成 (RAG) 技术，深入探索聊天交互的未来并探索您的文档。可以将文档加载到工作区的 `Documents` 标签中，之后可以使用井号键 [`#`] 在查询前访问它们，或者通过以井号键 [`#`] 开始提示，然后是网页内容集成的 URL。

- 📄 **文档提取**：从各种文档格式中提取文本和数据，包括 PDF、Word 文档、Excel 电子表格、PowerPoint 演示文稿等。我们先进的文档处理功能使其与您的知识库无缝集成，允许从复杂文档中准确检索和生成信息，同时保留其结构和格式。

- 🔍 **RAG 的网络搜索**：您可以使用各种搜索提供商进行网络搜索，并将结果直接注入到您的本地检索增强生成 (RAG) 体验中。

- 🌐 **网页浏览功能**：通过使用 `#` 命令后跟 URL，将网站无缝集成到您的聊天体验中。此功能使网页内容可以直接纳入您的对话，从而增强交互的丰富性和深度。

- 🎨 **图像生成集成**：无缝整合图像生成功能，用动态视觉内容丰富您的聊天体验。

- ⚙️ **并发模型利用**：轻松同时使用多个模型，利用它们的独特优势获得最佳响应。并行利用多种模型模态，增强您的体验。

- 🔐 **基于角色的访问控制 (RBAC)**：确保安全访问，权限受限。只有授权人员可以访问您的 Ollama，而模型创建和拉取权限专门保留给管理员。

- 🌐🌍 **多语言支持**：通过我们的国际化 (`i18n`) 支持，以您喜欢的语言体验 Open WebUI。我们邀请您加入我们，扩展我们支持的语言！我们正在积极寻找贡献者！

- 🌟 **持续更新**：我们致力于通过定期更新、修复和新功能改进 Open WebUI。

## 以及更多显著功能，包括... ⚡️

---

### 🔧 Pipelines 支持

- 🔧 **Pipelines 框架**：通过我们的模块化插件框架，无缝集成和定制您的 Open WebUI 体验，增强定制和功能 (https://github.com/open-webui/pipelines)。我们的框架允许轻松添加自定义逻辑和集成 Python 库，从 AI 代理到家庭自动化 API。

- 📥 **上传 Pipeline**：可以直接从 `管理面板` > `设置` > `Pipelines` 菜单上传 Pipelines，简化 pipeline 管理过程。

#### 我们的 Pipelines 框架的可能性无限，几乎没有界限。从一些预构建的 pipelines 开始，帮助您入门！

- 🔗 **函数调用**：通过 Pipelines 无缝集成 [函数调用](https://github.com/open-webui/pipelines/blob/main/examples/filters/function_calling_filter_pipeline.py)，通过高级函数调用功能增强您的 LLM 交互。

- 📚 **自定义 RAG**：无缝集成 [自定义检索增强生成 (RAG)](https://github.com/open-webui/pipelines/tree/main/examples/pipelines/rag) pipeline，通过自定义 RAG 逻辑增强您的 LLM 交互。

- 📊 **使用 Langfuse 的消息监控**：通过 [Langfuse](https://github.com/open-webui/pipelines/blob/main/examples/filters/langfuse_filter_pipeline.py) pipeline 实时监控和分析消息交互的使用统计数据。

- ⚖️ **用户速率限制**：通过控制发送到 LLM 的请求流，使用 [速率限制](https://github.com/open-webui/pipelines/blob/main/examples/filters/rate_limit_filter_pipeline.py) pipeline 有效管理 API 使用，防止超过速率限制。

- 🌍 **实时 LibreTranslate 翻译**：使用 [LibreTranslate](https://github.com/open-webui/pipelines/blob/main/examples/filters/libretranslate_filter_pipeline.py) pipeline 将实时翻译集成到您的 LLM 交互中，实现跨语言通信。
  - 请注意，此 pipeline 需要在 Docker 容器中进一步设置 LibreTranslate 才能工作。

- 🛡️ **有害消息过滤**：我们的 [Detoxify](https://github.com/open-webui/pipelines/blob/main/examples/filters/detoxify_filter_pipeline.py) pipeline 自动过滤有害消息，维护干净安全的聊天环境。

- 🔒 **LLM-Guard**：通过 [LLM-Guard](https://github.com/open-webui/pipelines/blob/main/examples/filters/llmguard_prompt_injection_filter_pipeline.py) pipeline 确保安全的 LLM 交互，其中包含提示注入扫描器，可检测和缓解针对大型语言模型的巧妙输入操作。这保护您的 LLM 免受数据泄漏，并增加对提示注入攻击的抵抗层。

- 🕒 **对话轮次限制**：通过 [对话轮次限制](https://github.com/open-webui/pipelines/blob/main/examples/filters/conversation_turn_limit_filter.py) pipeline 设置对话轮次限制，改进交互管理。

- 📈 **OpenAI 生成统计**：我们的 [OpenAI](https://github.com/open-webui/pipelines/blob/main/examples/pipelines/providers/openai_manifold_pipeline.py) pipeline 为 OpenAI 模型提供详细的生成统计数据。

- **🚀 多模型支持**：我们与 [各种提供商](https://github.com/open-webui/pipelines/tree/main/examples/pipelines/providers) 的各种 AI 模型的无缝集成扩展了您的可能性，提供广泛的语言模型供选择和交互。

#### 除了广泛的功能和定制选项外，我们还提供 [一个可直接使用的示例 pipelines 库](https://github.com/open-webui/pipelines/tree/main/examples) 以及 [一个实用的示例脚手架 pipeline](https://github.com/open-webui/pipelines/blob/main/examples/scaffolds/example_pipeline_scaffold.py) 帮助您入门。这些资源将简化您的开发过程，使您能够使用 Pipelines 和 Python 快速创建强大的 LLM 交互。编码愉快！💡

---

### 🖥️ 用户体验

- 🖥️ **直观界面**：聊天界面以用户为中心设计，灵感来自 ChatGPT 的用户界面。

- ⚡ **快速响应**：享受可靠的快速响应性能。

- 🎨 **启动屏幕**：简单的加载启动屏幕，提供更流畅的用户体验。

- 🌐 **个性化界面**：在设置 > 界面中选择全新设计的搜索登陆页面和经典聊天 UI，实现定制体验。

- 📦 **Pip 安装方法**：可以通过命令 `pip install open-webui` 安装 Open WebUI，简化流程，使新用户更容易访问。更多信息，请访问：https://pypi.org/project/open-webui/。

- 🌈 **主题定制**：通过一系列选项个性化您的 Open WebUI 体验，包括各种坚实而时尚的主题、可定制的聊天背景图像，以及三种模式选项：浅色、深色或 OLED 深色模式 - 或者让*她*为您选择！;)

- 🖼️ **自定义背景支持**：在设置 > 界面中设置自定义背景，个性化您的体验。

- 📝 **带有 Markdown 的丰富横幅**：在横幅中使用 markdown 支持创建视觉吸引力的公告，实现更丰富、更动态的内容。

- 💻 **代码语法高亮**：我们的语法高亮功能增强了代码可读性，提供清晰简洁的代码视图。

- 🗨️ **用户消息中的 Markdown 渲染**：用户消息现在以 Markdown 渲染，增强可读性和交互性。

- 🎨 **灵活的文本输入选项**：在聊天中切换富文本输入和传统文本区域输入，满足用户偏好，提供高级格式化和更简单的文本输入之间的选择。

- 👆 **轻松代码共享**：通过便捷的代码复制选项简化共享和协作过程，包括代码块中的浮动复制按钮和从代码段点击复制功能，节省时间并减少挫折感。

- 🎨 **交互式工件**：直接在界面中渲染网页内容和 SVG，支持快速迭代和实时更改，增强创造力和生产力。

- 🖊️ **实时代码编辑**：增强的代码块允许直接在 LLM 响应中进行实时编辑，工件支持实时重载，简化编码和测试。

- 🔍 **增强的 SVG 交互**：SVG 图像的平移和缩放功能，包括 Mermaid 图表，使深入探索和理解复杂概念成为可能。

- 🔍 **文本选择快速操作**：当在 LLM 响应中突出显示文本时，会出现浮动按钮，提供更深入的交互，如"提问"或"解释"，增强整体用户体验。

- ↕️ **双向聊天支持**：您可以轻松在从左到右和从右到左的聊天方向之间切换，以适应各种语言偏好。

- 📱 **移动端可访问性**：可以通过简单的滑动手势在移动设备上打开和关闭侧边栏。

- 🤳 **支持设备上的触觉反馈**：Android 设备支持触觉反馈，在某些交互期间提供沉浸式触觉体验。

- 🔍 **用户设置搜索**：快速搜索设置字段，提高易用性和导航性。

- 📜 **离线 Swagger 文档**：离线访问开发者友好的 Swagger API 文档，确保无论您身在何处都能完全访问。

- 💾 **性能优化**：大型依赖项的延迟加载最小化初始内存使用，提升性能并减少加载时间。

- 🚀 **持久和可扩展配置**：Open WebUI 配置存储在数据库 (webui.db) 中，允许无缝负载均衡、高可用性设置和跨多个实例的持久设置，使您轻松访问和重用配置。

- 🔄 **便携式导入/导出**：轻松导入和导出 Open WebUI 配置，简化跨多个系统复制设置的过程。

- ❓ **快速访问文档和快捷键**：位于主 UI 屏幕右下角的问号按钮（在台式电脑和笔记本电脑等较大屏幕上可用）为用户提供了轻松访问 Open WebUI 文档页面和可用键盘快捷键的途径。

- 📜 **更新日志和检查更新**：用户可以在 `设置` > `关于` > `查看新功能` 菜单中访问全面的更新日志并检查更新，该菜单提供最新功能、改进和错误修复的快速概览，以及检查更新的能力。

---

### 💬 对话

- 💬 **真正的异步聊天**：通过真正的异步聊天支持享受不间断的多任务处理，允许您创建聊天，离开，并随时返回，响应已准备就绪。

- 🔔 **聊天完成通知**：通过即时的 UI 内通知保持更新，当非活动标签中的聊天完成时，确保您永远不会错过完成的响应。

- 🌐 **通知 Webhook 集成**：通过可配置的 webhook 通知接收长时间运行的聊天或外部集成需求的及时更新，即使您的标签已关闭。

- 📚 **频道（测试版）**：通过 Discord/Slack 风格的聊天室探索用户和 AI 之间的实时协作，为频道构建机器人，并为主动多代理工作流解锁异步通信。

- 🖊️ **频道中的打字指示器**：通过频道中的实时打字指示器增强协作，保持每个人的参与和信息。

- 👤 **用户状态指示器**：通过点击频道中的用户个人资料图像快速查看用户状态，提供更好的协调和可用性洞察。

- 💬 **聊天控制**：轻松调整每个聊天会话的参数，提供对交互的更精确控制。

- 💖 **收藏响应管理**：直接从聊天概览轻松标记和组织收藏的响应，增强检索和访问首选响应的便捷性。

- 📌 **固定聊天**：支持固定聊天，允许您保持重要对话轻松访问。

- 🔍 **RAG 嵌入支持**：直接在 `管理面板` > `设置` > `文档` 菜单中更改检索增强生成 (RAG) 嵌入模型，增强文档处理。此功能支持 Ollama 和 OpenAI 模型。

- 📜 **RAG 功能中的引用**：检索增强生成 (RAG) 功能允许用户通过添加引用点轻松跟踪提供给 LLM 的文档上下文。

- 🌟 **增强的 RAG 管道**：我们的 RAG 嵌入功能的可切换混合搜索子功能，通过 `BM25` 增强 RAG 功能，由 `CrossEncoder` 提供重新排名，并具有可配置的相关性分数阈值。

- 📹 **YouTube RAG 管道**：专用于通过视频 URL 总结 YouTube 视频的检索增强生成 (RAG) 管道，实现与视频转录的流畅交互。

- 📁 **全面文档检索**：在完整文档检索和传统片段之间切换，实现全面任务如总结，并支持增强的文档功能。

- 🌟 **RAG 引用相关性**：通过在 RAG 结果中添加相关性百分比，轻松评估引用准确性。

- 🗂️ **高级 RAG**：通过在检索前智能预处理聊天历史以确定最佳查询，提高 RAG 准确性。

- 📚 **RAG 的内联引用**：受益于检索增强生成 (RAG) 响应的无缝内联引用，改进可追溯性并为新上传的文件提供源清晰度。

- 📁 **大文本处理**：可选择将大型粘贴文本转换为文件上传，直接用于 RAG，保持聊天界面更整洁。

- 🔄 **多模态支持**：轻松使用支持多模态交互的模型，包括图像（`例如，LLaVA`）。

- 🤖 **多模型支持**：快速在不同模型之间切换，实现多样化的聊天交互。

- 🔀 **在多模型聊天中合并响应**：通过将多个模型的响应合并为单一、连贯的回复，增强对话。

- ✅ **在聊天中支持同一模型的多个实例**：增强多模型聊天，支持添加同一模型的多个实例。

- 💬 **临时聊天功能**：引入临时聊天功能，弃用旧的聊天历史设置，以增强用户交互灵活性。

- 🖋️ **用户消息编辑**：增强用户聊天编辑功能，允许保存更改而不发送。

- 💬 **高效对话编辑**：使用 Cmd/Ctrl+Shift+Enter 快捷键快速直观地创建新消息对，简化对话长度测试。

- 🖼️ **客户端图像压缩**：通过客户端图像压缩节省带宽并提高性能，允许您在设置 > 界面中在上传前压缩图像。

- 👥 **'@' 模型集成**：通过在对话期间无缝切换到任何可访问的本地或外部模型，用户可以利用单个聊天中多个模型的集体智能。这可以通过使用 `@` 命令在聊天中按名称指定模型来完成。

- 🏷️ **对话标记**：使用我们高效的 'tag:' 查询系统轻松分类和定位标记的聊天，以便快速参考和简化数据收集，允许您管理、搜索和组织对话，而不会使界面混乱。

- 🧠 **自动标记**：对话可以选择自动标记以改进组织，反映自动生成标题的效率。

- 👶 **聊天克隆**：轻松克隆和保存任何聊天的快照，以供将来参考或继续。此功能使您可以轻松地从离开的地方继续，或与他人分享您的会话。要创建聊天副本，只需点击聊天下拉选项中的 `克隆` 按钮。您能跟上您的克隆吗？

- ⭐ **可视化对话流**：交互式消息图表，改进对话流的可视化，增强对复杂讨论的理解和导航。

- 📁 **聊天文件夹**：将聊天组织到文件夹中，拖放它们以便于管理，并无缝导出它们以共享或分析。

- 📤 **轻松聊天导入**：通过简单地将聊天导出（JSON）拖放到侧边栏上，将聊天导入到您的工作区。

- 📜 **提示预设支持**：使用聊天输入中的 `/` 命令即时访问自定义预设提示。轻松加载预定义的对话启动器，加速您的交互。通过 [Open WebUI Community](https://openwebui.com/) 集成轻松导入提示或创建您自己的提示！

- 📅 **提示变量支持**：提示变量如 `{{CLIPBOARD}}`、`{{CURRENT_DATE}}`、`{{CURRENT_DATETIME}}`、`{{CURRENT_TIME}}`、`{{CURRENT_TIMEZONE}}`、`{{CURRENT_WEEKDAY}}`、`{{USER_NAME}}`、`{{USER_LANGUAGE}}` 和 `{{USER_LOCATION}}` 可以在系统提示中使用，或通过使用斜杠命令直接在聊天中选择提示。
  - 请注意，`{{USER_LOCATION}}` 提示变量需要通过 HTTPS 的安全连接。要使用这个特定的提示变量，请确保从 `设置` > `界面` 菜单中切换开启 `{{USER_LOCATION}}`。
  - 请注意，`{{CLIPBOARD}}` 提示变量需要访问您设备的剪贴板。

- 🧠 **记忆功能**：通过 `设置` > `个性化` > `记忆` 菜单手动添加您希望 LLM 记住的信息。可以添加、编辑和删除记忆。

---

### 💻 模型管理


- 🛠️ **模型构建器**：所有模型都可以在模型编辑页面内的持久模型构建器模式中构建和编辑。

- 📚 **模型的知识支持**：能够直接从模型的编辑页面将工具、函数和知识集合附加到模型，增强每个模型可用的信息。

- 🗂️ **模型预设**：为 Ollama 和 OpenAI API 创建和管理模型预设。

- 🏷️ **模型标记**：模型工作区使用户能够使用标记组织他们的模型。

- 📋 **模型选择器下拉排序**：可以通过在模型工作区内拖放到所需位置轻松组织模型，这将在模型下拉菜单中反映更改。

- 🔍 **模型选择器下拉菜单**：使用模糊搜索和详细的模型信息轻松找到和选择您的模型，包括模型标签和模型描述。

- ⌨️ **箭头键模型选择**：使用箭头键更快速地选择模型，增强可访问性。

- 🔧 **模型工作区中的快速操作**：增强的 Shift 键快速操作，用于在模型工作区中隐藏/显示和删除模型。

- 😄 **透明模型使用**：通过可见状态显示，在使用知识增强模型进行查询期间了解系统状态。

- ⚙️ **使用高级参数的精细控制**：通过调整模型参数如 `seed`、`temperature`、`frequency penalty`、`context length`、`seed` 等获得更深层次的控制。

- 🔄 **无缝集成**：直接从 [Ollama library](https://ollama.com/library/) 上的模型页面复制任何 `ollama run {model:tag}` CLI 命令，并将其粘贴到模型下拉菜单中，轻松选择和拉取模型。

- 🗂️ **创建 Ollama Modelfile**：要为 Ollama 创建模型文件，导航到 `管理面板` > `设置` > `模型` > `创建模型` 菜单。

- ⬆️ **GGUF 文件模型创建**：通过从 `管理设置` > `设置` > `模型` > `实验性` 菜单直接从 Open WebUI 上传 GGUF 文件，轻松创建 Ollama 模型。该过程已经简化，可以选择从您的机器上传或从 Hugging Face 下载 GGUF 文件。

- ⚙️ **默认模型设置**：新聊天的默认模型偏好可以在移动设备上的 `设置` > `界面` 菜单中设置，或者在台式电脑和笔记本电脑上更容易地在新聊天的模型选择器下拉菜单中设置。

- 💡 **LLM 响应洞察**：可以查看每个生成的响应的详细信息，包括外部模型 API 洞察和全面的本地模型信息。

- 🕒 **一目了然的模型详情**：直接在模型工作区查看关键模型详情，包括模型哈希和最后修改时间戳，增强跟踪和管理。

- 📥🗑️ **下载/删除模型**：可以直接从 Open WebUI 轻松下载或删除模型。

- 🔄 **更新所有 Ollama 模型**：一个便捷的按钮允许用户在一次操作中更新所有本地安装的模型，简化模型管理。

- 🍻 **TavernAI 角色卡集成**：在我们的模型构建器中体验增强的视觉讲故事，通过 TavernAI 角色卡集成。用户可以将 TavernAI 角色卡 PNG 无缝整合到他们的模型文件中，创造更具沉浸感和吸引力的用户体验。

- 🎲 **模型游乐场（测试版）**：使用模型游乐场区域（`测试版`）尝试模型，该区域使用户能够在沙盒环境中轻松测试和探索模型功能和参数，然后再部署到实时聊天环境中。

---

### 👥 协作

- 🗨️ **本地聊天共享**：以高效无缝的方式在用户之间生成和共享聊天链接，从而增强协作和沟通。

- 👍👎 **RLHF 注释**：通过用竖起大拇指或竖下大拇指对消息进行评分，并在 1-10 分的范围内为响应提供评分，然后选择提供文本反馈，增强消息的影响力，促进为人类反馈强化学习（`RLHF`）创建数据集。利用您的消息训练或微调模型，同时确保本地保存数据的机密性。

- 🔧 **全面反馈导出**：将反馈历史数据导出为 JSON，以便与 RLHF 处理无缝集成并进行进一步分析，提供有价值的改进见解。

- 🤝 **社区共享**：通过点击 `分享到 Open WebUI 社区` 按钮，与 [Open WebUI Community](https://openwebui.com/) 分享您的聊天会话。此功能允许您与其他用户互动并在平台上协作。
  - 要使用此功能，请登录您的 Open WebUI Community 账户。分享您的聊天促进了充满活力的社区，鼓励知识共享，并促进联合解决问题。请注意，聊天会话的社区共享是一个可选功能。只有管理员可以在 `管理设置` > `设置` > `常规` 菜单中打开或关闭此功能。

- 🏆 **社区排行榜**：通过我们的排行榜系统实时竞争和跟踪您的表现，该系统使用 ELO 评级系统，并允许可选共享反馈历史。

- ⚔️ **模型评估竞技场**：直接从管理设置进行模型的盲目 A/B 测试，进行真正的并排比较，使找到最适合您需求的模型变得更容易。

- 🎯 **基于主题的排名**：通过我们的实验性基于主题的重新排名系统发现更准确的排名，该系统根据反馈中的标签相似性调整排行榜排名。

- 📂 **统一和协作工作区**：在一个便捷的位置访问和管理所有模型文件、提示、文档、工具和函数，同时使多个用户能够协作并为模型、知识、提示或工具做出贡献，简化您的工作流程并增强团队合作。

---

### 📚 历史和归档

- 📜 **聊天历史**：通过聊天导航侧边栏轻松访问和管理您的对话历史。在 `设置` > `聊天` 菜单中关闭聊天历史，以防止在新交互中创建聊天历史。

- 🔄 **重新生成历史访问**：轻松重新访问和探索您的整个 LLM 响应重新生成历史。

- 📬 **归档聊天**：轻松存储您与模型进行的已完成对话，以供将来参考或交互，保持整洁无杂乱的聊天界面。

- 🗃️ **归档所有聊天**：此功能允许您一次性快速归档所有聊天。

- 📦 **将所有归档聊天导出为 JSON**：此功能使用户能够轻松将所有归档聊天导出为单个 JSON 文件，可用于备份或传输目的。

- 📄 **将聊天下载为 JSON/PDF/TXT**：轻松以您喜欢的 `.json`、`.pdf` 或 `.txt` 格式单独下载您的聊天。

- 📤📥 **导入/导出聊天历史**：通过 `导入聊天` 和 `导出聊天` 选项无缝移动您的聊天数据进出平台。

- 🗑️ **删除所有聊天**：此选项允许您永久删除所有聊天，确保重新开始。

---

### 🎙️ 音频、语音和可访问性

- 🗣️ **语音输入支持**：通过语音交互与您的模型互动；享受直接与模型交谈的便利。此外，探索在 3 秒静默后自动发送语音输入的选项，以获得流畅的体验。
  - 麦克风访问需要手动设置通过 HTTPS 的安全连接才能工作，或者[自行承担风险手动将您的 URL 列入白名单](https://docs.openwebui.com/troubleshooting/microphone-error)。

- 😊 **表情符号通话**：从 `设置` > `界面` 菜单打开此功能，允许 LLM 在语音通话期间使用表情符号表达情感，实现更动态的交互。
  - 此功能需要通过 HTTPS 的安全连接访问麦克风才能工作。

- 🎙️ **免提语音通话功能**：无需使用手即可发起语音通话，使交互更加无缝。
  - 此功能需要使用通过 HTTPS 的安全连接访问麦克风。

- 📹 **视频通话功能**：启用与支持视觉的模型（如 LlaVA 和 GPT-4o）的视频通话，为您的通信添加视觉维度。
  - 此功能需要使用通过 HTTPS 的安全连接访问摄像头和麦克风。

- 👆 **点击中断**：在移动设备上通过简单点击停止 AI 在语音对话中的讲话，确保对交互的无缝控制。

- 🎙️ **语音中断**：在移动设备上通过您的声音停止 AI 在语音对话中的讲话，确保对交互的无缝控制。

- 🔊 **可配置的文本转语音端点**：通过可配置的 OpenAI 兼容端点自定义您的文本转语音体验，用于朗读 LLM 响应。

- 🔗 **直接通话模式访问**：直接从 URL 激活通话模式，为移动设备用户提供便捷的快捷方式。

- ✨ **可定制的文本转语音**：控制消息内容如何分段用于文本转语音 (TTS) 生成请求，允许灵活的语音输出选项。

- 🔊 **Azure 语音服务集成**：支持 Azure 语音服务用于文本转语音 (TTS)，为用户提供更广泛的语音合成选项。

- 🎚️ **可定制的音频播放**：允许用户在通话模式设置中调整音频播放速度以满足其偏好，增强可访问性和可用性。

- 🎵 **广泛的音频兼容性**：享受对 RAG 的各种音频文件格式转录的支持，包括 'audio/x-m4a'，以扩大与平台内音频内容的兼容性。

- 🔊 **音频压缩**：实验性音频压缩允许绕过 OpenAI 语音转文本处理的 25MB 限制，扩展基于音频的交互可能性。

- 🗣️ **实验性 SpeechT5 TTS**：享受本地 SpeechT5 支持，改进文本转语音功能。

---

### 🐍 代码执行

- 🚀 **多功能、UI 无关、OpenAI 兼容的插件框架**：无缝集成和定制 [Open WebUI Pipelines](https://github.com/open-webui/pipelines) 用于高效数据处理和模型训练，确保最终的灵活性和可扩展性。

- 🛠️ **原生 Python 函数调用**：通过原生函数调用直接在 Open WebUI 中访问 Python 的强大功能。轻松集成自定义代码，通过内置代码编辑器构建独特功能，如自定义 RAG 管道、网络搜索工具，甚至代理类操作，在 `工具` 和 `函数` 工作区内无缝开发和集成函数代码。

- 🐍 **Python 代码执行**：通过 Pyodide 在浏览器中本地执行 Python 代码，支持 Pyodide 支持的一系列库。

- 🌊 **Mermaid 渲染**：使用 [Mermaid 图表和制图工具](https://mermaid.js.org/intro/) 直接在 Open WebUI 中创建视觉吸引力的图表和流程图，该工具支持 Mermaid 语法渲染。

- 🔗 **Iframe 支持**：使用函数和工具直接将 HTML 渲染到您的聊天界面中。

---

### 🔒 集成和安全

- ✨ **多种 OpenAI 兼容 API 支持**：无缝集成和定制各种 OpenAI 兼容的 API，增强聊天交互的多功能性。

- 🔑 **简化的 API 密钥管理**：轻松生成和管理密钥，以利用 OpenAI 库使用 Open WebUI，简化集成和开发。

- 🌐 **HTTP/S 代理支持**：使用 `http_proxy` 或 `https_proxy` 环境变量轻松配置网络设置。如果设置，这些变量应包含 HTTP 和 HTTPS 代理的 URL。

- 🌐🔗 **外部 Ollama 服务器连接**：通过配置环境变量无缝链接到托管在不同地址的外部 Ollama 服务器。

- 🛢️ **灵活的数据库集成**：使用环境变量无缝连接到自定义数据库，包括 SQLite、Postgres 和多个向量数据库如 Milvus，实现灵活和可扩展的数据管理。

- 🌐🗣️ **外部语音转文本支持**：添加外部语音转文本（`STT`）服务提供增强的灵活性，允许用户选择他们喜欢的提供商进行无缝交互。

- 🌐 **远程 ChromaDB 支持**：通过连接到远程 ChromaDB 服务器扩展数据库的功能。

- 🔀 **多 Ollama 实例负载均衡**：轻松将聊天请求分布到多个 Ollama 实例，以增强性能和可靠性。

- 🚀 **高级负载均衡和可靠性**：利用增强的负载均衡功能、具有完整 Redis 支持的无状态实例和自动网络套接字重新连接，促进 WebUI 中更好的性能、可靠性和可扩展性，确保跨多个实例的无缝和不间断交互。

- ☁️ **实验性 S3 支持**：启用带有 S3 支持的无状态 WebUI 实例，以增强可扩展性和平衡繁重工作负载。

- 🛠️ **用户组的 OAuth 管理**：通过 OAuth 集成增强协作环境中的控制和可扩展性，实现组级管理。

---

### 👑 管理

- 👑 **超级管理员分配**：自动将第一个注册用户分配为超级管理员，具有不可更改的角色，任何人都无法修改，甚至其他管理员也不能。

- 🛡️ **精细用户权限**：通过可定制的基于角色的权限限制用户操作和访问，确保只有授权人员可以执行特定任务。

- 👥 **多用户管理**：带有分页的直观管理面板，允许您无缝管理多个用户，简化用户管理和用户生命周期管理。

- 🔧 **管理面板**：用户管理系统旨在简化用户入职和管理，提供直接添加用户或通过 CSV 导入批量添加用户的选项。

- 👥 **活跃用户指示器**：监控活跃用户数量以及哪些模型被谁使用，以帮助评估由于大量用户可能影响性能的时间。

- 🔒 **默认注册角色**：将新注册的默认角色指定为 `待定`、`用户` 或 `管理员`，为新用户提供管理权限和访问级别的灵活性。

- 🔒 **防止新注册**：启用禁用新用户注册的选项，限制对平台的访问并维持固定数量的用户。

- 🔒 **防止聊天删除**：管理员能够切换一个设置，防止所有用户删除他们的聊天消息，确保所有聊天消息都保留用于审计或合规目的。

- 🔗 **Webhook 集成**：通过 webhook（兼容 `Discord`、`Google Chat`、`Slack` 和 `Microsoft Teams`）订阅新用户注册事件，提供实时通知和自动化功能。

- 📣 **可配置的通知横幅**：管理员可以创建可定制的横幅，在 config.json 中持久保存，具有内容、背景颜色（`info`、`warning`、`error` 或 `success`）和可关闭性的选项。横幅仅对已登录用户可访问，确保敏感信息的机密性。

- 🛡️ **模型白名单**：通过允许管理员为具有 `user` 角色的用户设置模型白名单，增强安全性和访问控制，确保只能访问授权模型。

- 🔑 **社区共享的管理控制**：管理员可以通过 `管理面板` > `设置` 菜单中的切换开关为所有用户启用或禁用社区共享。此切换允许管理员管理可访问性和隐私，确保安全环境。管理员可以选择为所有用户启用或禁用 `分享到社区` 按钮，使他们能够控制社区参与和协作。

- 📧 **可信电子邮件认证**：可选择使用可信电子邮件标头进行认证，为您的 Open WebUI 实例添加额外的安全层和认证。

- 🔒 **后端反向代理支持**：通过 Open WebUI 的后端和 Ollama 之间的直接通信增强安全性。这一关键功能消除了通过本地区域网络 (LAN) 暴露 Ollama 的需要。从 Open WebUI 到 `/ollama/api` 路由的请求从后端无缝重定向到 Ollama，增强整体系统安全性并提供额外的保护层。

- 🔒 **认证**：请注意，Open WebUI 本身不支持联合认证方案，如 SSO、OAuth、SAML 或 OIDC。然而，它可以配置为将认证委托给认证反向代理，有效实现单点登录（`SSO`）体验。此设置允许您集中用户认证和管理，增强安全性和用户便利性。通过将 Open WebUI 与认证反向代理集成，您可以利用现有认证系统并简化用户对 Open WebUI 的访问。有关配置此功能的更多信息，请参阅 [联合认证支持](https://docs.openwebui.com/features/sso)。

- 🔓 **可选认证**：通过将 `WEBUI_AUTH` 设置为 `False` 享受禁用认证的灵活性。这是没有现有用户的新安装的理想解决方案，或者可用于演示目的。

- 🚫 **高级 API 安全**：基于自定义模型过滤器阻止 API 用户，增强 API 访问的安全性和控制。

- ❗ **管理员更新**：确保管理员通过登录时的即时更新通知保持信息，使他们了解最新变化和系统状态。

- 👥 **用户组管理**：创建和管理用户组，实现无缝组织和控制。

- 🔐 **基于组的访问控制**：基于用户组设置对模型、知识、提示和工具的精细访问，允许更受控和安全的环境。

- 🛠️ **精细用户权限**：轻松管理工作区权限，包括文件上传、删除、编辑和临时聊天，以及模型、知识、提示和工具创建。

- 🔑 **LDAP 认证**：通过 LDAP 支持增强用户管理的安全性和可扩展性。

- 🌐 **可定制的 OpenAI 连接**：通过自定义 OpenAI 设置享受流畅操作，包括前缀 ID 支持和 API 的显式模型 ID 支持。

- 🔐 **Ollama API 密钥管理**：管理 Ollama 凭证，包括前缀 ID 支持，以实现安全高效的操作。

- 🔄 **连接管理**：根据需要轻松启用或禁用单个 OpenAI 和 Ollama 连接。

- 🎨 **直观的模型工作区**：通过重新设计的用户友好界面，跨用户和组管理模型。

- 🔑 **API 密钥认证**：通过轻松启用或禁用 API 密钥认证加强安全性。

- 🔄 **统一模型重置**：通过一键选项从管理设置重置和删除所有模型。

- 🔓 **灵活的模型访问控制**：在不需要时，使用 'BYPASS_MODEL_ACCESS_CONTROL' 环境变量轻松绕过用户角色的模型访问控制，简化受信任环境中的工作流程。

- 🔒 **可配置的 API 密钥认证限制**：灵活配置 API 密钥认证的端点限制，现在默认关闭，以在受信任环境中实现更顺畅的设置。
